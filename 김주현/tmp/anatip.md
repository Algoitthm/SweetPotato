## 분석 대분류

1. 예측분석
2. 분류분석
3. 수요예측
   1. 단기적으로 이동평균 MA나 지수평활법
   2. Arima 다중선형회귀
4. 추천개인화
5. 최적화
6. 텍스트마이닝
7. 기초통계분석
8. 딥러닝
   1. (Data/언어/시각 AI)
9. 세분화
10. 품질 등 원인인자 분석
   11. CNN 불량예측
   12. Bayesian Network를 활용한 이상원인 해석 및 변수간 인과관계
13. 이상감지(설비예지보전, FDS등)
    1. 분류모델과 군집화 기법을 활용한 이상패턴 탐지
14. 군집분석(개인화)
15. 추천분석(상품추천)
16. Text Analytics
    1. word2vec
       1. skip gram 방식 : 중심단어를 사용하여 주변단어를 예측한다.
       2. CBOW 방식 : 주변 단어를 사용하여 중심단어를 예측한다.



## 머신러닝의 종류

1. 지도학습

   1. FDS(사기적발), 음성이미지인식, 이메일분류
   2. Tree계열 : 결정트리, RF
   3. network계열 : 로지스틱, 뉴럴
   4. 커널계열 : SVM

2. 비지도학습

   1. 클러스터링, 문서분류. 고객Segmentation

   2. Distance이용 : Hierarchy cluster

   3. Centroid이용 : K-means, EM알고리즘

      

## 설명력

1. 있음
   1. KNN
   2. Decision Tree
   3. Logistic regression
      1. 독립 to 종속변수 영향 직관적
      2. Odds비 산출
      3. 신용평가모형에서 스코어 산출에 사용



## 분석 순서

1. 분석 목표수립
   1. 모델링 알고리즘 파악
   2. 평가기준 수립
2. 데이터 마트구성
3. EDA해서 알고리즘 적용가능성 파악
4. 데이터 전처리 및 파생변수 도출
5. 알고리즘 적용
6. 최적 모델 선택
7. 모형의 결과 시각화



## 예시별 분석법

1. 통신사 해지방어 모델 (카드사기 적발 유사)
   1. 상세
      1. 검색이력 , 고객 데이터
      2. 1개월 이내 해지여부 예측
   2. 해결
      1. Decision Tree로 주요 해지요인 분석
      2. RF, 인공신경망으로 예측정확도 상승
2. 보험FDS (퇴직예측 유사)
   1. 상세
      1. 보험 청구건으로 사기유형 및 사기여부 예측
   2. 해결
      1. 사기 유형을 비슷한것 끼리 클러스터링
         1. PCA를 통해 5차원벡터를 분산이 최대인 2차원으로 수정
      2. 사기유형 별로 사기위험 예측모델 구현
         1. 로지스틱 회귀 사용
            1. 독립변수간 다중공산성 제거(상관관계 높은 것)
            2. 불필요 변수 제거
               1. AIC 산출로 변수를 하나씩 지워가며 모델 변별력 확인
            3. 변수간 스케일 일치
               1. 아웃라이어 제거를 위해 범주형 변수로 변환
            4. 사기건수:정상건수 유사
               1. 사기건 오버샘플링
               2. 정상건 언더샘플링
3. 텍스트분석
   1. 텍스트 전처리
      1. 불용어, 어간분석, 품사 태깅, Syntactic Parsing
      2. 변환
         1. 수치적으로 변환
      3. Feature Selection
         1. LSA LDA 나이브베이즈, SVM 등



## 데이터 분석 클라우드 환경

1. AWS
   1. Kinesis : 실시간 스트리밍 데이터 수집, 기본은 ETL이지만 java확장하여 스트리밍데이터분석에 사용
   2. SageMaker : 머신러닝 모델 학습, 배포
   3. EC2 : 가상서버
   4. S3 : 스토리지
   5. Athena : S3에 SQL쿼리
   6. RedShift : 데이터 웨어하우스만들기
   7. QuichSight : BI툴
   8. EMR : 분산프레임워크 제공
2. DAP MLDL
   1. 원천 데이터는 SBP플랫폼에서 가져옴(Data Lake)
   2. Paxata :전처리
   3. 노트북에서 모델 개발
   4. 모델 저장
   5. 평가지표와 목표점수 입력
   6. 이 과정을 job으로 배치진행
   7. 각 결과에 대해 모니터링
3. AutoML
   1. 변수 선정 및 유관데이터 선별 필요, 다양한 접근 방식의 분석가 필요
   2. 하나의 데이터 테이블화 해주어야 함
4. PySpark
   1. Spark SQL : SQL쿼리로 데이터처리 용이
   2. MLlib : 머신러닝
   3. Spark Streaming : 스트리밍 데이터처리
   4. GraphX : 그래프 분석
5. Databricks
   1. Azure 기반
      1. delta : 데이터 전처리 손쉽게 사용, 아파치 스파크와 100% 연동
      2. Collaborative Notebook : 다양한 노트북 제공, 배치. 대쉬보드, BI툴 가능
      3. MLR : conda환경과 동일, 머신러닝 패키지 다수 설치
      4. Augmented 머신러닝 기능 제공  / 모델관리 : 수많은 experiment에 대한 추적과 비교분석, 기록관리, 최적 모델탐색 제공, 하이퍼파라미터 자동튜닝 



AWS, Azure, GCP 비교

- 머신러닝 온 클라우드 :  Azure 기능 많고, 드래그드랍가능
- STT TTS : Azure기능 많음
- 이미지분석 : GCP 기능 많음
- 비디오 : Azure 기능 많음, AWS만 스트리밍비디오 분석제공
